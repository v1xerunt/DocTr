{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3403 425 426\n"
     ]
    }
   ],
   "source": [
    "trial2idx = pickle.load(open('./data/trial2idx.pkl', 'rb'))\n",
    "npi2idx = pickle.load(open('./data/npi2idx.pkl', 'rb'))\n",
    "trial2npi = pickle.load(open('./data/trial2npi.pkl', 'rb'))\n",
    "\n",
    "trial_info = pickle.load(open('./data/trial_info.pkl', 'rb'))\n",
    "\n",
    "trial_list = list(trial2idx.keys())\n",
    "trial_date = [trial_info[trial]['start_date'] for trial in trial_list]\n",
    "# Sort the trial list by start date\n",
    "trial_list = [trial for _, trial in sorted(zip(trial_date, trial_list))]\n",
    "\n",
    "\n",
    "\n",
    "# Split the trial list into train, val, and test in a 80/10/10 ratio\n",
    "train_list = trial_list[:int(len(trial_list)*0.8)]\n",
    "val_list = trial_list[int(len(trial_list)*0.8):int(len(trial_list)*0.9)]\n",
    "test_list = trial_list[int(len(trial_list)*0.9):]\n",
    "\n",
    "print(len(train_list), len(val_list), len(test_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NCT04003480'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(train_list, open('./data/zero_shot/train_list.pkl', 'wb'))\n",
    "pickle.dump(val_list, open('./data/zero_shot/val_list.pkl', 'wb'))\n",
    "pickle.dump(test_list, open('./data/zero_shot/test_list.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gen atomic files\n",
    "def gen_atomic_file(trial_list, file_name):\n",
    "    header = 'user_id:token\\titem_id:token'\n",
    "    row_list = []\n",
    "    for each_trial in trial_list:\n",
    "        for each_npi in trial2npi[each_trial]:            \n",
    "            cur_row = '%s\\t%s' % (trial2idx[each_trial], npi2idx[each_npi])\n",
    "            row_list.append(cur_row)\n",
    "    with open(file_name, 'w') as f:\n",
    "        f.write('%s\\n' % header)\n",
    "        for each_row in row_list:\n",
    "            f.write('%s\\n' % each_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_atomic_file(train_list, './atomic/trial_zero/trial_zero.train.inter')\n",
    "gen_atomic_file(val_list, './atomic/trial_zero/trial_zero.val.inter')\n",
    "gen_atomic_file(test_list, './atomic/trial_zero/trial_zero.test.inter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial2pool = pickle.load(open('./data/trial2pool.pkl', 'rb'))\n",
    "npi_codes = pickle.load(open('./data/npi_codes.pkl', 'rb'))\n",
    "\n",
    "trial_condition = pickle.load(open('./data/trial_condition.pkl', 'rb'))\n",
    "trial_summary = pickle.load(open('./data/trial_summary.pkl', 'rb'))\n",
    "npi2trial = pickle.load(open('./data/npi2trial.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1718,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_condition['NCT00004451'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate clinician embd file\n",
    "# Normalize embd\n",
    "npi_mat = np.array([npi_codes[each_npi] for each_npi in npi_codes])\n",
    "npi_mean, npi_std = np.mean(npi_mat, axis=0), np.std(npi_mat, axis=0)\n",
    "norm_npi_codes = {}\n",
    "# for each_npi in npi_codes:\n",
    "#     norm_npi_codes[each_npi] = (npi_codes[each_npi] - npi_mean) / (npi_std + 1e-7)\n",
    "for each_npi in npi_codes:\n",
    "    norm_npi_codes[each_npi] = (npi_codes[each_npi] - np.mean(npi_codes[each_npi])) / (np.std(npi_codes[each_npi]) + 1e-7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate clinician embd file\n",
    "# Normalize embd\n",
    "npi_mat = np.array([npi_codes[each_npi] for each_npi in npi_codes])\n",
    "npi_mean, npi_std = np.mean(npi_mat, axis=0), np.std(npi_mat, axis=0)\n",
    "norm_npi_codes2 = {}\n",
    "for each_npi in npi_codes:\n",
    "    norm_npi_codes2[each_npi] = (npi_codes[each_npi] - npi_mean) / (npi_std + 1e-7)\n",
    "# for each_npi in npi_codes:\n",
    "#     norm_npi_codes[each_npi] = (npi_codes[each_npi] - np.mean(npi_codes[each_npi])) / (np.std(npi_codes[each_npi]) + 1e-7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate external feature file for trials\n",
    "header = 'user_id:token\\tuser_feat:float_seq\\tuser_info:float_seq\\tuser_summary:float_seq'\n",
    "row_list = []\n",
    "for i in range(len(trial_list)):\n",
    "    cur_embd = trial2pool[trial_list[i]]\n",
    "    row = str(i) + '\\t'\n",
    "    for j in range(len(cur_embd)):\n",
    "        row += str(cur_embd[j]) + ' '\n",
    "    row = row[:-1]\n",
    "    \n",
    "    row += '\\t'\n",
    "    cur_info = trial_condition[trial_list[i]]\n",
    "    for j in range(len(cur_info)):\n",
    "        row += str(cur_info[j]) + ' '\n",
    "    row = row[:-1]\n",
    "    \n",
    "    row += '\\t'\n",
    "    cur_sum = trial_summary[trial_list[i]]\n",
    "    for j in range(len(cur_sum)):\n",
    "        row += str(cur_sum[j]) + ' '\n",
    "    row = row[:-1]\n",
    "    \n",
    "    row_list.append(row)\n",
    "with open('../atomic/trial_zero/trial_zero.user', 'w') as f:\n",
    "    f.write('%s\\n' % header)\n",
    "    for each_row in row_list:\n",
    "        f.write('%s\\n' % each_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate clinician embd file\n",
    "# Normalize embd\n",
    "header = 'item_id:token\\titem_feat:float_seq\\titem_his:float_seq\\titem_feat_2:float_seq'\n",
    "\n",
    "row_list = []\n",
    "for each_npi in norm_npi_codes:\n",
    "    if each_npi not in npi2idx:\n",
    "        continue\n",
    "    cur_embd = norm_npi_codes[each_npi]\n",
    "    row = str(npi2idx[each_npi]) + '\\t'\n",
    "    for j in range(len(cur_embd)):\n",
    "        row += str(cur_embd[j]) + ' '\n",
    "    row = row[:-1]\n",
    "    \n",
    "    row += '\\t'\n",
    "    cur_his = npi2trial[each_npi]\n",
    "    his_list = []\n",
    "    for each_trial in cur_his:\n",
    "        if each_trial in train_list:\n",
    "            his_list.append(trial2pool[each_trial])\n",
    "    if len(his_list) == 0:\n",
    "        his_list.append(np.zeros(768))\n",
    "\n",
    "    cur_his = np.array(his_list).mean(axis=0)\n",
    "    for j in range(len(cur_his)):\n",
    "        row += str(cur_his[j]) + ' '\n",
    "    row = row[:-1]\n",
    "    \n",
    "    row += '\\t'\n",
    "    cur_embd = norm_npi_codes2[each_npi]\n",
    "    for j in range(len(cur_embd)):\n",
    "        row += str(cur_embd[j]) + ' '\n",
    "    row = row[:-1]\n",
    "    row_list.append(row)\n",
    "    \n",
    "\n",
    "with open('./atomic/trial_zero/trial_zero.item', 'w') as f:\n",
    "    f.write('%s\\n' % header)\n",
    "    for each_row in row_list:\n",
    "        f.write('%s\\n' % each_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24524, 26242)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(npi2idx), len(npi_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15.754113775270334, 27.18856131253795, 6.0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_list = []\n",
    "for each_trial in trial2npi:\n",
    "    len_list.append(len(trial2npi[each_trial]))\n",
    "np.mean(len_list), np.std(len_list), np.median(len_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
