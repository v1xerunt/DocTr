{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import getLogger\n",
    "from recbole.utils import init_logger, init_seed\n",
    "from recbole.trainer import Trainer\n",
    "from custom.light_gcn import LightGCN\n",
    "from custom.custom_model_gcn import Doctr\n",
    "from recbole.config import Config\n",
    "from recbole.data import create_dataset, data_preparation\n",
    "import pickle\n",
    "from recbole.utils.case_study import full_sort_scores, full_sort_topk\n",
    "import torch\n",
    "\n",
    "from utils import com_sim, max_sim\n",
    "from genetic import genetic_algorithm, calc_metrics\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config(model=Doctr, dataset='trial_zero', config_file_list=[\"./atomic/doctr.yaml\"])\n",
    "init_seed(config['seed'], config['reproducibility'])\n",
    "\n",
    "# logger initialization\n",
    "init_logger(config)\n",
    "logger = getLogger()\n",
    "\n",
    "logger.info(config)\n",
    "\n",
    "# dataset filtering\n",
    "dataset = create_dataset(config)\n",
    "#dataset = pickle.load(open('./dataset.pkl', 'rb'))\n",
    "logger.info(dataset)\n",
    "print('-------------')\n",
    "\n",
    "# dataset splitting\n",
    "train_data, valid_data, test_data = data_preparation(config, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Doctr(config, train_data.dataset).to(config['device'])\n",
    "trainer = Trainer(config, model)\n",
    "trainer.eval_collector.data_collect(train_data)\n",
    "trainer.eval_collector.model_collect(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14 May 18:24    INFO  Loading model structure and parameters from ../models/doctr.pth\n"
     ]
    }
   ],
   "source": [
    "test_result = trainer.evaluate(test_data, model_file='./models/doctr.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_trials = pickle.load(open('./data/zero_shot/test_list.pkl', 'rb'))\n",
    "trial2idx = pickle.load(open('./data/trial2idx.pkl', 'rb'))\n",
    "npi2idx = pickle.load(open('./data/npi2idx.pkl', 'rb'))\n",
    "idx2npi = {v: k for k, v in npi2idx.items()}\n",
    "trial2npi = pickle.load(open('./data/trial2npi.pkl', 'rb'))\n",
    "npi_info = pickle.load(open('./data/npi_info_dict.pkl', 'rb'))\n",
    "trial2category = pickle.load(open('./data/trial2category.pkl', 'rb'))\n",
    "trial2phase = pickle.load(open('./data/trial_phase.pkl', 'rb'))\n",
    "\n",
    "zip2fips = pickle.load(open('./data/zip2fips.pkl', 'rb'))\n",
    "fips2demo = pickle.load(open('./data/fips2demo.pkl', 'rb'))\n",
    "fips2state = pickle.load(open('./data/fips2state.pkl', 'rb'))\n",
    "\n",
    "competing_dict = pickle.load(open('./data/zero_shot/competing_dict.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embd(trial_name):\n",
    "    trial_idx = [str(trial2idx[trial_name])]\n",
    "    trial_series = dataset.token2id(dataset.uid_field, trial_idx)\n",
    "    scores = full_sort_scores(trial_series, model, test_data, device=config['device'])\n",
    "    topk_scores, topk_indices = full_sort_topk(trial_series, model, test_data, k=100, device=config['device'])\n",
    "    topk_scores = topk_scores.cpu().numpy()\n",
    "    topk_indices = topk_indices.cpu().numpy()\n",
    "    y_rec_embd = model.item_embedding_global(torch.tensor(topk_indices).to(config['device']))\n",
    "    \n",
    "    gt_npi = trial2npi[trial_name]\n",
    "    if len(gt_npi) == 0:\n",
    "        return None, None\n",
    "    gt_npi_idx = []\n",
    "    for npi in gt_npi:\n",
    "        gt_npi_idx.append(str(npi2idx[npi]))\n",
    "    gt_npi_idx = dataset.token2id(dataset.iid_field, gt_npi_idx)\n",
    "    gt_npi_embd = model.item_embedding_global(torch.tensor(gt_npi_idx).to(config['device']))\n",
    "    \n",
    "    return y_rec_embd.cpu().numpy(), gt_npi_embd.unsqueeze(0).cpu().numpy(), topk_scores, topk_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 426/426 [00:03<00:00, 120.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6010147\n",
      "0.60231626\n",
      "0.6037619\n",
      "0.5981742\n"
     ]
    }
   ],
   "source": [
    "sim_gt = []\n",
    "sim_5 = []\n",
    "sim_10 = []\n",
    "sim_20 = []\n",
    "score = []\n",
    "k_indexs = []\n",
    "k_scores = []\n",
    "trial_idx = []\n",
    "for i in tqdm(range(len(test_trials))):\n",
    "    res = get_embd(test_trials[i])\n",
    "    if res[0] is None:\n",
    "        continue\n",
    "    y_pred, y_true, k_score, k_index = res\n",
    "    \n",
    "    score.append(max_sim(y_true, y_pred).squeeze())\n",
    "    sim_gt.append(com_sim(y_true, y_pred, -1))\n",
    "    sim_5.append(com_sim(y_true, y_pred, 5))\n",
    "    sim_10.append(com_sim(y_true, y_pred, 10))\n",
    "    sim_20.append(com_sim(y_true, y_pred, 20))\n",
    "    k_indexs.append(k_index.squeeze())\n",
    "    k_scores.append(k_score.squeeze())\n",
    "    trial_idx.append(test_trials[i])\n",
    "\n",
    "# y_pred, y_true = get_embd(test_trials[3][0], 10)\n",
    "# com_sim(y_true, y_pred)\n",
    "print(np.mean(sim_gt))\n",
    "print(np.mean(sim_5))\n",
    "print(np.mean(sim_10))\n",
    "print(np.mean(sim_20))\n",
    "k_indexs = np.array(k_indexs)\n",
    "k_scores = np.array(k_scores)\n",
    "score = np.array(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.48865393\n",
      "0.6300379\n",
      "0.74652463\n",
      "0.53898644\n",
      "98 146 103 29\n"
     ]
    }
   ],
   "source": [
    "phase_res = {}\n",
    "for phase in range(1, 5):\n",
    "    phase_res[phase] = []\n",
    "    for i in range(len(trial_idx)):\n",
    "        if trial_idx[i] not in trial2phase or trial2phase[trial_idx[i]] == None:\n",
    "            continue\n",
    "        if ('Phase ' + str(phase)) in trial2phase[trial_idx[i]]:\n",
    "            phase_res[phase].append(sim_gt[i])\n",
    "    print(np.mean(phase_res[phase]))\n",
    "print(len(phase_res[1]), len(phase_res[2]), len(phase_res[3]), len(phase_res[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.424258\n",
      "0.51669663\n",
      "0.7597169\n",
      "0.7697163\n",
      "0.780276\n",
      "54 35 37 31 30\n"
     ]
    }
   ],
   "source": [
    "category_res = {}\n",
    "for category in ['Oncology', 'Cardiology', 'Neurology', 'Endocrinology', 'Infectious Disease']:\n",
    "    category_res[category] = []\n",
    "    for i in range(len(trial_idx)):\n",
    "        if trial_idx[i] not in trial2category or trial2category[trial_idx[i]] == None:\n",
    "            continue\n",
    "        if category in trial2category[trial_idx[i]]:\n",
    "            category_res[category].append(sim_gt[i])\n",
    "    print(np.mean(category_res[category]))\n",
    "print(len(category_res['Oncology']), len(category_res['Cardiology']), len(category_res['Neurology']), len(category_res['Endocrinology']), len(category_res['Infectious Disease']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the NPIs in the top predictions on the test set\n",
    "npi_ids = dataset.id2token(dataset.iid_field, k_indexs)\n",
    "npi_tokens = []\n",
    "for each_t in npi_ids:\n",
    "    cur_tokens = []\n",
    "    for npi_id in each_t:\n",
    "        cur_tokens.append(idx2npi[int(npi_id)])\n",
    "    npi_tokens.append(cur_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genetic_batch = []\n",
    "for idx, each_trial in enumerate(npi_tokens):\n",
    "    # Get top 10 NPIs\n",
    "    # Construct data struct\n",
    "    # [score, [gender ratio], [race ratio], [ethnicity ratio], [fips code]]\n",
    "    cur_batch = []\n",
    "    normed_k_scores = (k_scores[idx] - np.min(k_scores[idx])) / (np.max(k_scores[idx]) - np.min(k_scores[idx]))\n",
    "    for idx2, each_npi in enumerate(each_trial):\n",
    "        cur_zip = npi_info[each_npi]['Zip_Code']\n",
    "        if '-'  in cur_zip:\n",
    "            cur_zip = cur_zip.split('-')[0]\n",
    "        cur_zip = int(cur_zip)\n",
    "        cur_fips = zip2fips.get(cur_zip)\n",
    "        if cur_fips is not None and cur_fips in fips2demo:\n",
    "            cur_score = score[idx, idx2]\n",
    "            cur_gender = [fips2demo[cur_fips]['male'], fips2demo[cur_fips]['female']]\n",
    "            cur_race = [fips2demo[cur_fips]['white'], fips2demo[cur_fips]['black'], fips2demo[cur_fips]['indian'], fips2demo[cur_fips]['asian'], fips2demo[cur_fips]['native']]\n",
    "            cur_ethnicity = [fips2demo[cur_fips]['nonhis'], fips2demo[cur_fips]['his']]\n",
    "            cur_compete = competing_dict[test_trials[i]][each_npi]\n",
    "            cur_batch.append([cur_score, cur_gender, cur_race, cur_ethnicity, fips2state[cur_fips], cur_compete, idx2])\n",
    "        else:\n",
    "            cur_compete = competing_dict[test_trials[i]][each_npi]\n",
    "            cur_batch.append([normed_k_scores[idx2], fips2demo['national_average']['gender'], fips2demo['national_average']['race'], fips2demo['national_average']['ethnicity'], cur_compete, idx2])\n",
    "    genetic_batch.append(cur_batch)\n",
    "        #cur_batch.append([score[idx, idx2], npi_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 425/425 [02:53<00:00,  2.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.59525104 0.99940004 0.47320528 0.74243828 0.66698868 0.03388235]\n"
     ]
    }
   ],
   "source": [
    "total_res = []\n",
    "for idx in tqdm(range(len(genetic_batch))):\n",
    "    res = genetic_algorithm(genetic_batch[idx], 10, 50, 10)\n",
    "    total_res.append(calc_metrics(res, score[idx]))\n",
    "print(np.mean(total_res, axis=0))\n",
    "# CS@GT, Gender, Race, Ethnicity, Geo, Competing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "425it [00:00, 16991.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.56622701 0.99943507 0.42647336 0.59356979 0.67120661 4.68941176]\n"
     ]
    }
   ],
   "source": [
    "base_res = []\n",
    "for idx, each_batch in tqdm(enumerate(genetic_batch)):\n",
    "    # Random choice 10 NPIs\n",
    "    random_choice = np.random.choice(len(each_batch), 10, replace=False)\n",
    "    chosen = [each_batch[i] for i in random_choice]\n",
    "    base_res.append(calc_metrics(chosen, score[idx]))\n",
    "print(np.mean(base_res, axis=0))\n",
    "# CS@GT, Gender, Race, Ethnicity, Geo, Competing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
