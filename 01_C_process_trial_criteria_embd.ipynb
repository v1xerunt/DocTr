{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import openai\n",
    "import numpy as np\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, AutoModel\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/ie_extracted_clinical_trials.tsv','rb') as f:\n",
    "    df = pd.read_csv(f,sep='\\t')\n",
    "    df = df[df['eligibility_type'] == 'inclusion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "746360"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['criterion'].apply(lambda x: len(x.split())).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at medicalai/ClinicalBERT were not used when initializing DistilBertModel: ['vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel.from_pretrained(\"medicalai/ClinicalBERT\", trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"medicalai/ClinicalBERT\", trust_remote_code=True, model_max_length=512, truncation=True, max_length=512)\n",
    "extractor = pipeline(model=model, tokenizer=tokenizer, task=\"feature-extraction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "34825it [06:58, 83.26it/s] \n"
     ]
    }
   ],
   "source": [
    "trial2criterion = {}\n",
    "trial2embd = {}\n",
    "for idx, row in tqdm(df.iterrows()):\n",
    "    cur_nct = row['#nct_id']\n",
    "    if cur_nct not in trial2criterion:\n",
    "        trial2criterion[cur_nct] = []\n",
    "        trial2embd[cur_nct] = []\n",
    "    trial2criterion[cur_nct].append(row['criterion'])\n",
    "    \n",
    "    # Extract embeddings from text row['criterion']\n",
    "    cur_embd = extractor(row['criterion'], truncation=True, max_length=512)\n",
    "    \n",
    "    # Generate the sentence embedding\n",
    "    cur_embd = np.array(cur_embd).squeeze().mean(0)\n",
    "    trial2embd[cur_nct].append(cur_embd)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(trial2criterion, open('./data/trial2criterion.pkl','wb'))\n",
    "pickle.dump(trial2embd, open('./data/trial2embd.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4254/4254 [00:00<00:00, 62328.64it/s]\n"
     ]
    }
   ],
   "source": [
    "trial2pool = {}\n",
    "for trial in tqdm(trial2embd):\n",
    "    # Get the average embedding for each trial\n",
    "    trial2pool[trial] = np.array(trial2embd[trial]).mean(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(trial2pool, open('./data/trial2pool.pkl','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
