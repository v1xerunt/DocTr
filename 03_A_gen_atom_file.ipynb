{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of relationships: 67018\n",
      "54284 6032 6702\n"
     ]
    }
   ],
   "source": [
    "trial2idx = pickle.load(open('./data/trial2idx.pkl', 'rb'))\n",
    "npi2idx = pickle.load(open('./data/npi2idx.pkl', 'rb'))\n",
    "trial2npi = pickle.load(open('./data/trial2npi.pkl', 'rb'))\n",
    "\n",
    "relationship_list = []\n",
    "for each in trial2npi:\n",
    "    for npi in trial2npi[each]:\n",
    "        relationship_list.append((each, npi))\n",
    "print('Number of relationships:', len(relationship_list))\n",
    "\n",
    "# Split the trial list into train, val, and test in a 80/10/10 ratio\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_list, test_list = train_test_split(relationship_list, test_size=0.1, random_state=42)\n",
    "train_list, val_list = train_test_split(train_list, test_size=0.1, random_state=42)\n",
    "print(len(train_list), len(val_list), len(test_list))\n",
    "\n",
    "# # Split the trial list into train, val, and test in a 80/10/10 ratio\n",
    "# train_list = trial_list[:int(len(trial_list)*0.8)]\n",
    "# val_list = trial_list[int(len(trial_list)*0.8):int(len(trial_list)*0.9)]\n",
    "# test_list = trial_list[int(len(trial_list)*0.9):]\n",
    "\n",
    "# print(len(train_list), len(val_list), len(test_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(train_list, open('./data/full_shot/train_list.pkl', 'wb'))\n",
    "pickle.dump(val_list, open('./data/full_shot/val_list.pkl', 'wb'))\n",
    "pickle.dump(test_list, open('./data/full_shot/test_list.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gen atomic files\n",
    "def gen_atomic_file(rel_list, file_name):\n",
    "    header = 'user_id:token\\titem_id:token'\n",
    "    row_list = []\n",
    "    for each_rel in rel_list:\n",
    "        each_trial, each_npi = each_rel         \n",
    "        cur_row = '%s\\t%s' % (trial2idx[each_trial], npi2idx[each_npi])\n",
    "        row_list.append(cur_row)\n",
    "    with open(file_name, 'w') as f:\n",
    "        f.write('%s\\n' % header)\n",
    "        for each_row in row_list:\n",
    "            f.write('%s\\n' % each_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_atomic_file(train_list, './atomic/trial/trial.train.inter')\n",
    "gen_atomic_file(val_list, './atomic/trial/trial.val.inter')\n",
    "gen_atomic_file(test_list, './atomic/trial/trial.test.inter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial2pool = pickle.load(open('./data/trial2pool.pkl', 'rb'))\n",
    "npi_codes = pickle.load(open('./data/npi_codes.pkl', 'rb'))\n",
    "\n",
    "trial_condition = pickle.load(open('./data/trial_condition.pkl', 'rb'))\n",
    "trial_summary = pickle.load(open('./data/trial_summary.pkl', 'rb'))\n",
    "npi2trial = pickle.load(open('./data/npi2trial.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1718,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "npi_codes['1003002817'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate clinician embd file\n",
    "# Normalize embd\n",
    "npi_mat = np.array([npi_codes[each_npi] for each_npi in npi_codes])\n",
    "npi_mean, npi_std = np.mean(npi_mat, axis=0), np.std(npi_mat, axis=0)\n",
    "norm_npi_codes = {}\n",
    "# for each_npi in npi_codes:\n",
    "#     norm_npi_codes[each_npi] = (npi_codes[each_npi] - npi_mean) / (npi_std + 1e-7)\n",
    "for each_npi in npi_codes:\n",
    "    norm_npi_codes[each_npi] = (npi_codes[each_npi] - np.mean(npi_codes[each_npi])) / (np.std(npi_codes[each_npi]) + 1e-7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate clinician embd file\n",
    "# Normalize embd\n",
    "npi_mat = np.array([npi_codes[each_npi] for each_npi in npi_codes])\n",
    "npi_mean, npi_std = np.mean(npi_mat, axis=0), np.std(npi_mat, axis=0)\n",
    "norm_npi_codes2 = {}\n",
    "for each_npi in npi_codes:\n",
    "    norm_npi_codes2[each_npi] = (npi_codes[each_npi] - npi_mean) / (npi_std + 1e-7)\n",
    "# for each_npi in npi_codes:\n",
    "#     norm_npi_codes[each_npi] = (npi_codes[each_npi] - np.mean(npi_codes[each_npi])) / (np.std(npi_codes[each_npi]) + 1e-7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate external feature file for trials\n",
    "header = 'user_id:token\\tuser_feat:float_seq\\tuser_info:float_seq\\tuser_summary:float_seq'\n",
    "row_list = []\n",
    "done_trials = set()\n",
    "for i in range(len(relationship_list)):\n",
    "    cur_trial = relationship_list[i][0]\n",
    "    if cur_trial in done_trials:\n",
    "        continue\n",
    "    done_trials.add(cur_trial)\n",
    "    cur_embd = trial2pool[cur_trial]\n",
    "    row = str(trial2idx[cur_trial]) + '\\t'\n",
    "    for j in range(len(cur_embd)):\n",
    "        row += str(cur_embd[j]) + ' '\n",
    "    row = row[:-1]\n",
    "    \n",
    "    row += '\\t'\n",
    "    cur_info = trial_condition[cur_trial]\n",
    "    for j in range(len(cur_info)):\n",
    "        row += str(cur_info[j]) + ' '\n",
    "    row = row[:-1]\n",
    "    \n",
    "    row += '\\t'\n",
    "    cur_sum = trial_summary[cur_trial]\n",
    "    for j in range(len(cur_sum)):\n",
    "        row += str(cur_sum[j]) + ' '\n",
    "    row = row[:-1]\n",
    "    \n",
    "    row_list.append(row)\n",
    "with open('../atomic/trial/trial.user', 'w') as f:\n",
    "    f.write('%s\\n' % header)\n",
    "    for each_row in row_list:\n",
    "        f.write('%s\\n' % each_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate clinician embd file\n",
    "# Normalize embd\n",
    "header = 'item_id:token\\titem_feat:float_seq\\titem_his:float_seq\\titem_feat_2:float_seq'\n",
    "\n",
    "row_list = []\n",
    "for each_npi in norm_npi_codes:\n",
    "    if each_npi not in npi2idx:\n",
    "        continue\n",
    "    cur_embd = norm_npi_codes[each_npi]\n",
    "    row = str(npi2idx[each_npi]) + '\\t'\n",
    "    for j in range(len(cur_embd)):\n",
    "        row += str(cur_embd[j]) + ' '\n",
    "    row = row[:-1]\n",
    "    \n",
    "    row += '\\t'\n",
    "    cur_his = npi2trial[each_npi]\n",
    "    his_list = []\n",
    "    for each_trial in cur_his:\n",
    "        if each_trial in train_list:\n",
    "            his_list.append(trial2pool[each_trial])\n",
    "    if len(his_list) == 0:\n",
    "        his_list.append(np.zeros(768))\n",
    "\n",
    "    cur_his = np.array(his_list).mean(axis=0)\n",
    "    for j in range(len(cur_his)):\n",
    "        row += str(cur_his[j]) + ' '\n",
    "    row = row[:-1]\n",
    "    \n",
    "    row += '\\t'\n",
    "    cur_embd = norm_npi_codes2[each_npi]\n",
    "    for j in range(len(cur_embd)):\n",
    "        row += str(cur_embd[j]) + ' '\n",
    "    row = row[:-1]\n",
    "    row_list.append(row)\n",
    "    \n",
    "\n",
    "with open('./atomic/trial/trial.item', 'w') as f:\n",
    "    f.write('%s\\n' % header)\n",
    "    for each_row in row_list:\n",
    "        f.write('%s\\n' % each_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24524, 26242)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(npi2idx), len(npi_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15.754113775270334, 27.18856131253795, 6.0)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_list = []\n",
    "for each_trial in trial2npi:\n",
    "    len_list.append(len(trial2npi[each_trial]))\n",
    "np.mean(len_list), np.std(len_list), np.median(len_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
